1st ► VOTE pod ► Observe what happens both in frontEnd & in Unix

after deletion , new vote pod came up 

[root@ip-172-31-31-224 k8s-specifications]# kubectl get all
NAME                          READY   STATUS    RESTARTS   AGE
pod/db-b54cd94f4-cwcvx        1/1     Running   0          8m24s
pod/redis-868d64d78-txb5c     1/1     Running   0          15m
pod/result-5d57b59f4b-xn48w   1/1     Running   1          15m
pod/vote-94849dc97-rfmns      1/1     Running   0          31s
pod/worker-dd46d7584-s62m5    1/1     Running   1          10m

NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
service/db           ClusterIP   10.111.128.175   <none>        5432/TCP         15m
service/kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP          16m
service/redis        ClusterIP   10.108.192.185   <none>        6379/TCP         15m
service/result       NodePort    10.108.27.138    <none>        5001:31001/TCP   15m
service/vote         NodePort    10.98.223.4      <none>        5000:31000/TCP   15m

NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/db       1/1     1            1           15m
deployment.apps/redis    1/1     1            1           15m
deployment.apps/result   1/1     1            1           15m
deployment.apps/vote     1/1     1            1           15m
deployment.apps/worker   1/1     1            1           15m

NAME                                DESIRED   CURRENT   READY   AGE
replicaset.apps/db-b54cd94f4        1         1         1       15m
replicaset.apps/redis-868d64d78     1         1         1       15m
replicaset.apps/result-5d57b59f4b   1         1         1       15m
replicaset.apps/vote-94849dc97      1         1         1       15m
replicaset.apps/worker-dd46d7584    1         1         1       15m

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2nd ► WORKER pod  ► Observe what happens both in frontEnd & in Unix

after deletion , worker pod came up nothing happened

[root@ip-172-31-31-224 k8s-specifications]# kubectl get all
NAME                          READY   STATUS    RESTARTS   AGE
pod/db-b54cd94f4-cwcvx        1/1     Running   0          16m
pod/redis-868d64d78-txb5c     1/1     Running   0          23m
pod/result-5d57b59f4b-xn48w   1/1     Running   1          23m
pod/vote-94849dc97-rfmns      1/1     Running   0          8m41s
pod/worker-dd46d7584-w54r4    1/1     Running   0          114s

NAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
service/db           ClusterIP   10.111.128.175   <none>        5432/TCP         23m
service/kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP          24m
service/redis        ClusterIP   10.108.192.185   <none>        6379/TCP         23m
service/result       NodePort    10.108.27.138    <none>        5001:31001/TCP   23m
service/vote         NodePort    10.98.223.4      <none>        5000:31000/TCP   23m

NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/db       1/1     1            1           23m
deployment.apps/redis    1/1     1            1           23m
deployment.apps/result   1/1     1            1           23m
deployment.apps/vote     1/1     1            1           23m
deployment.apps/worker   1/1     1            1           23m

NAME                                DESIRED   CURRENT   READY   AGE
replicaset.apps/db-b54cd94f4        1         1         1       23m
replicaset.apps/redis-868d64d78     1         1         1       23m
replicaset.apps/result-5d57b59f4b   1         1         1       23m
replicaset.apps/vote-94849dc97      1         1         1       23m
replicaset.apps/worker-dd46d7584    1         1         1       23m

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

3rd ► DB pod ► Observe what happens both in frontEnd & in Unix"

--> After deletion, vote count became zero as old db pod was deleted as result all the vote transction was also deleted.
and result and worker pod also goes into error state as well when db pod terminates

[root@ip-172-31-20-86 ~]# kubectl get pods
NAME                      READY   STATUS        RESTARTS   AGE
db-b54cd94f4-b55vw        1/1     Terminating   0          9m2s
db-b54cd94f4-fmstq        1/1     Running       0          31s
redis-868d64d78-txb5c     1/1     Running       0          33m
result-5d57b59f4b-xn48w   0/1     Error         2          33m
vote-94849dc97-5blfs      1/1     Running       0          2m14s
worker-dd46d7584-4wztb    0/1     Error         0          2m

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
what happens after db pod deletion?

--> result and worker pod also goes into error state as well when db pod terminates


[root@ip-172-31-20-86 ~]# kubectl get pods
NAME                      READY   STATUS        RESTARTS   AGE
db-b54cd94f4-b55vw        1/1     Terminating   0          9m2s
db-b54cd94f4-fmstq        1/1     Running       0          31s
redis-868d64d78-txb5c     1/1     Running       0          33m
result-5d57b59f4b-xn48w   0/1     Error         2          33m
vote-94849dc97-5blfs      1/1     Running       0          2m14s
worker-dd46d7584-4wztb    0/1     Error         0          2m


[root@ip-172-31-31-224 k8s-specifications]# kubectl get all
NAME                          READY   STATUS    RESTARTS   AGE
pod/db-b54cd94f4-fmstq        1/1     Running   0          8m37s
pod/redis-868d64d78-txb5c     1/1     Running   0          41m
pod/result-5d57b59f4b-xn48w   1/1     Running   3          41m
pod/vote-94849dc97-5blfs      1/1     Running   0          10m
pod/worker-dd46d7584-4wztb    1/1     Running   1          10m

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
complete the assignment by making the result pod work.
--> new pods are created automatically  

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
comment on WHY result app STOPPED working after db pod stop

--> as the DB connection is lost , result and worker pod went into error state as old DB was terminating and it restarts, once its connected to new DB pod it cames to running state. 


